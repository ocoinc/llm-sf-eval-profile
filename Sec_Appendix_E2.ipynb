{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771f700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load raw data\n",
    "df = pd.read_csv('official_row_data.csv', encoding='utf-8')\n",
    "\n",
    "# Pivot to wide format\n",
    "df_cross = (\n",
    "    df\n",
    "    .set_index(['story', 'model', 'session'])['score']\n",
    "    .unstack(['model', 'session'])\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename columns to 'model-session'\n",
    "df_cross.columns = [\n",
    "    col if isinstance(col, str) else f\"{col[0]}-{col[1]}\"\n",
    "    for col in df_cross.columns\n",
    "]\n",
    "\n",
    "# Extract numeric matrix for PCA\n",
    "X = df_cross.drop('story-', axis=1).values\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# PCA\n",
    "pca = PCA()\n",
    "loadings = pca.fit(X_scaled).components_.T * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "# Format loadings\n",
    "max_pcs = min(4, X.shape[1])\n",
    "loadings_df = pd.DataFrame(\n",
    "    loadings[:, :max_pcs],\n",
    "    index=df_cross.columns[1:],\n",
    "    columns=[f'PC{i+1}' for i in range(max_pcs)]\n",
    ").reset_index().rename(columns={'index': 'session_id'})\n",
    "\n",
    "# Clustering (K=5)\n",
    "X_pca = loadings_df[[f'PC{i+1}' for i in range(max_pcs)]].values\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "loadings_df['cluster'] = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Merge cluster labels back\n",
    "df['session_id'] = df['model'] + '-' + df['session'].astype(str)\n",
    "df = pd.merge(df, loadings_df[['session_id', 'cluster']], on='session_id', how='left')\n",
    "\n",
    "# Remove specific sessions\n",
    "drop_list = [f'Notebook LM-{i}' for i in range(2, 8)]\n",
    "df_filtered = df[~df['session_id'].isin(drop_list)]\n",
    "\n",
    "# Group comments by cluster\n",
    "comments = {\n",
    "    cluster: df_filtered[df_filtered['cluster'] == cluster]['comment'].dropna().tolist()\n",
    "    for cluster in sorted(df_filtered['cluster'].unique())\n",
    "}\n",
    "\n",
    "# Text preprocessing\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "custom_stopwords = [\n",
    "    'the', 'a', 'an', 'in', 'on', 'of', 'to', 'with', 'at', 'by', 'for', 'from',\n",
    "    'is', 'are', 'was', 'were', 'be', 'being', 'been',\n",
    "    'that', 'this', 'these', 'those', 'and', 'but', 'or', 'if', 'then', 'so',\n",
    "    'as', 'because', 'while', 'although', 'though', 'yet', 'also', 'just', 'it',\n",
    "    'its', 'fs', 'about', 'ai', 'narrative', 'story', 'through', 'slightly',\n",
    "    'somewhat', 'effectively', 'well', 'occasionally'\n",
    "]\n",
    "\n",
    "# TF-IDF per cluster\n",
    "ranking = []\n",
    "for cluster_id, texts in comments.items():\n",
    "    processed = [preprocess_text(t) for t in texts]\n",
    "    vectorizer = TfidfVectorizer(stop_words=custom_stopwords)\n",
    "    tfidf_matrix = vectorizer.fit_transform(processed)\n",
    "\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    mean_scores = tfidf_matrix.mean(axis=0).A1\n",
    "    tfidf_scores = dict(zip(feature_names, mean_scores))\n",
    "\n",
    "    top_words = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "    for rank, (word, _) in enumerate(top_words, 1):\n",
    "        ranking.append([cluster_id, rank, word])\n",
    "\n",
    "# Create pivot table\n",
    "df_keywords = pd.DataFrame(ranking, columns=['cluster', 'rank', 'word'])\n",
    "pivot_df = df_keywords.pivot(index='rank', columns='cluster', values='word')\n",
    "pivot_df.columns = [f'Cluster {i}' for i in pivot_df.columns]\n",
    "\n",
    "# Display\n",
    "print(\"\\nTable E-2: Top 10 TF-IDF Words per Cluster\")\n",
    "print(pivot_df)\n",
    "\n",
    "print(\"\\nTable E-2: Number of Comments per Cluster\")\n",
    "for cluster_id, comment_list in comments.items():\n",
    "    print(f\"Cluster {cluster_id}: {len(comment_list)} comments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d5eba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
